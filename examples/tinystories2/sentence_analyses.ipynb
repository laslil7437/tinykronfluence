{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer\n",
    "import torch \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Original \n",
    "train_data = load_from_disk(\"hf_dataset/sentence_train\")\n",
    "eval_data = load_from_disk(\"hf_dataset/sentence_eval\")\n",
    "top50_idx = torch.load(\"results_sentences/sentential_negation_npi_licensor_present/top_indices.pt\")\n",
    "bottom50_idx = torch.load(\"results_sentences/sentential_negation_npi_licensor_present/bottom_indices.pt\")\n",
    "\n",
    "# Augmented\n",
    "# train_data_aug = load_from_disk(\"hf_dataset/sentence_train_augmented\")\n",
    "# eval_data_aug = load_from_disk(\"hf_dataset/sentence_eval_augmented\")\n",
    "# top50_idx_aug = torch.load(\"results_sentences/sentential_negation_npi_licensor_present_augmented/top_indices.pt\")\n",
    "# bottom50_idx_aug = torch.load(\"results_sentences/sentential_negation_npi_licensor_present_augmented/bottom_indices.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# decode texts and put into df\n",
    "def decode_df(indices, train_data):\n",
    "    idx_arr = indices.numpy()\n",
    "    flat_idx_arr = idx_arr.flatten()\n",
    "\n",
    "    decoded_texts = [\n",
    "        tokenizer.decode(train_data[int(idx)][\"input_ids\"], skip_special_tokens=True)\n",
    "        for idx in flat_idx_arr\n",
    "    ]\n",
    "\n",
    "    decoded_array = np.array(decoded_texts).reshape(idx_arr.shape)\n",
    "\n",
    "    decoded_df = pd.DataFrame(decoded_array)\n",
    "    \n",
    "    return decoded_df\n",
    "\n",
    "top_df = decode_df(top50_idx, train_data)\n",
    "bottom_df = decode_df(bottom50_idx, train_data)\n",
    "# top_df_aug = decode_df(top50_idx_aug, train_data_aug)\n",
    "# bottom_df_aug = decode_df(bottom50_idx_aug, train_data_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The school had not ever intended to conspire.',\n",
       " 'The school had probably ever intended to conspire.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 249\n",
    "blimp1_good = tokenizer.decode(eval_data[\"input_ids_good\"][idx], skip_special_tokens=True)\n",
    "blimp1_bad = tokenizer.decode(eval_data[\"input_ids_bad\"][idx], skip_special_tokens=True)\n",
    "blimp1_good, blimp1_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top 50</th>\n",
       "      <th>Bottom 50</th>\n",
       "      <th>Top 50 Augmented</th>\n",
       "      <th>Bottom 50 Augmented</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Top 50  Bottom 50  Top 50 Augmented  Bottom 50 Augmented\n",
       "0         0          2                 0                    2\n",
       "1         0          0                 0                    0\n",
       "2         0          0                 0                    0\n",
       "3         0          0                 1                    0\n",
       "4         0          1                 0                    1\n",
       "..      ...        ...               ...                  ...\n",
       "245       0          0                 0                    0\n",
       "246       0          0                 0                    0\n",
       "247       0          0                 0                    0\n",
       "248       0          3                 2                    4\n",
       "249       0          0                 0                    0\n",
       "\n",
       "[250 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# Define the phrase to search for, using regex\n",
    "# phrase = re.compile(r\"\\bever\\b\")\n",
    "# phrase = re.compile(r\"\\bnot ever\\b\")\n",
    "\n",
    "# phrase = re.compile(r\"(?:not|n't)\\b.*\\bever\\b\", flags=re.IGNORECASE)\n",
    "# not or n't followed by ever, but does not include any occurrences of \"happily ever after\" or superlatives before the word 'ever'\n",
    "phrase = re.compile(r\"\\b(?:not|n't)\\b(?![^.]{0,50}happily ever after)(?![^.]{0,50}(?:est|most|worst|favorite|least)).*?\\bever\\b\", flags=re.IGNORECASE)\n",
    "\n",
    "# phrase = re.compile(r\"\\b(?:no one|nobody|nothing)\\b(?![^.]{0,50}happily ever after).*?\\bever\\b\", flags=re.IGNORECASE)\n",
    "# phrase = re.compile(r\"(than).*\\bever\\b\", flags=re.IGNORECASE)\n",
    "# phrase = re.compile(r\"\\bif\\b.*\\bever\\b\", flags=re.IGNORECASE)\n",
    "# phrase = re.compile(r\"\\bever\\b.*\\?\")\n",
    "# phrase = re.compile(r\"(?:est|most|worst|favorite|least).*\\bever\\b\", flags=re.IGNORECASE)\n",
    "# phrase = re.compile(r\"(?:est|most|worst|favorite|least).{1,8}?\\bever\\b\", flags=re.IGNORECASE)\n",
    "# phrase = re.compile(r\"\\bhappily ever after\\b\", flags=re.IGNORECASE)\n",
    "\n",
    "# phrase = re.compile(r\"\\b(?:any|yet)\\b\", flags=re.IGNORECASE)\n",
    "# phrase = re.compile(r\".*\\b(?:not|never|n't)\\b.*\\b(?:any|yet)\\b.*\", flags=re.IGNORECASE)\n",
    "\n",
    "# phrase = re.compile(r\"\\bonly\\b\", flags=re.IGNORECASE)\n",
    "# phrase = re.compile(r\"\\bonly\\b.*\\b(?:any|yet|ever)\\b.*\", flags=re.IGNORECASE)\n",
    "# phrase = re.compile(r\"\\bonly\\b.*\\byet\\b.*\", flags=re.IGNORECASE)\n",
    "\n",
    "phrase_count_df = pd.DataFrame({\n",
    "    \"Top 50\": top_df.apply(lambda row: sum(bool(phrase.search(text)) for text in row), axis=1),\n",
    "    \"Bottom 50\": bottom_df.apply(lambda row: sum(bool(phrase.search(text)) for text in row), axis=1),\n",
    "    \"Top 50 Augmented\": top_df_aug.apply(lambda row: sum(bool(phrase.search(text)) for text in row), axis=1),\n",
    "    \"Bottom 50 Augmented\": bottom_df_aug.apply(lambda row: sum(bool(phrase.search(text)) for text in row), axis=1)\n",
    "})\n",
    "# sentences with the phrase\n",
    "sentences_df = pd.DataFrame({\n",
    "    \"Top 50\": top_df.apply(lambda row: [text for text in row if phrase.search(text)], axis=1),\n",
    "    \"Bottom 50\": bottom_df.apply(lambda row: [text for text in row if phrase.search(text)], axis=1),\n",
    "    \"Top 50 Augmented\": top_df_aug.apply(lambda row: [text for text in row if phrase.search(text)], axis=1),\n",
    "    \"Bottom 50 Augmented\": bottom_df_aug.apply(lambda row: [text for text in row if phrase.search(text)], axis=1)\n",
    "})\n",
    "phrase_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 Phrase Avg: 0.104\n",
      "Top 50 Phrase Total: 26\n",
      "Bottom 50 Phrase Avg: 0.344\n",
      "Bottom 50 Phrase Total: 86\n",
      "Top 50 Augmented Phrase Avg: 0.192\n",
      "Top 50 Augmented Phrase Total: 48\n",
      "Bottom 50 Augmented Phrase Avg: 0.352\n",
      "Bottom 50 Augmented Phrase Total: 88\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 50 Phrase Avg:\", phrase_count_df[\"Top 50\"].mean())\n",
    "print(\"Top 50 Phrase Total:\", phrase_count_df[\"Top 50\"].sum())\n",
    "print(\"Bottom 50 Phrase Avg:\", phrase_count_df[\"Bottom 50\"].mean())\n",
    "print(\"Bottom 50 Phrase Total:\", phrase_count_df[\"Bottom 50\"].sum())\n",
    "print(\"Top 50 Augmented Phrase Avg:\", phrase_count_df[\"Top 50 Augmented\"].mean())\n",
    "print(\"Top 50 Augmented Phrase Total:\", phrase_count_df[\"Top 50 Augmented\"].sum())\n",
    "print(\"Bottom 50 Augmented Phrase Avg:\", phrase_count_df[\"Bottom 50 Augmented\"].mean())\n",
    "print(\"Bottom 50 Augmented Phrase Total:\", phrase_count_df[\"Bottom 50 Augmented\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“I will not ever try to touch something so big again!”',\n",
       " 'The girl did not ever want to drop ice again.',\n",
       " 'Mia did not ever want to be in this place again.',\n",
       " 'Mia did not ever want to be in this place again.',\n",
       " 'Mia did not ever want to be in this place again.',\n",
       " 'Max had not seen it ever before!',\n",
       " 'Max had not seen it ever before!',\n",
       " \"But don't ever touch that button again.\",\n",
       " 'Mia did not ever want to be in this place again.',\n",
       " 'Max had not seen it ever before!',\n",
       " 'Max had not seen it ever before!',\n",
       " 'Max had not seen it ever before!',\n",
       " \"But don't ever touch that button again.\",\n",
       " 'Max had not seen it ever before!',\n",
       " 'Annie waved goodbye and she was sure she would not ever forget this amazing creature',\n",
       " 'Annie waved goodbye and she was sure she would not ever forget this amazing creature',\n",
       " 'Mia did not ever want to be in this place again.',\n",
       " 'I didn\\'t think I\\'d ever get it to the top by myself.\"',\n",
       " '“I will not ever try to touch something so big again!”',\n",
       " 'He decided that he would not pinch anyone ever again.',\n",
       " 'Annie waved goodbye and she was sure she would not ever forget this amazing creature',\n",
       " \"The bear couldn't sing ever again.\",\n",
       " '“I will not ever try to touch something so big again!”',\n",
       " 'Max had not seen it ever before!',\n",
       " 'Everyone could not ever get enough of her magical cakes.',\n",
       " 'They could not remember ever making such a big and good structure together.',\n",
       " 'The doctor gave her medicine, and told her not to ever touch strange plants again',\n",
       " 'Max had not seen it ever before!',\n",
       " 'Max had not seen it ever before!',\n",
       " \"But don't ever touch that button again.\",\n",
       " 'The girl did not ever want to drop ice again.',\n",
       " 'Mia did not ever want to be in this place again.',\n",
       " \"But don't ever touch that button again.\",\n",
       " 'Max had not seen it ever before!',\n",
       " 'Max had not seen it ever before!',\n",
       " 'Max had not seen it ever before!',\n",
       " 'Max had not seen it ever before!',\n",
       " '“I will not ever try to touch something so big again!”',\n",
       " 'Everyone could not ever get enough of her magical cakes.',\n",
       " '“I will not ever try to touch something so big again!”',\n",
       " 'The girl did not ever want to drop ice again.',\n",
       " 'They could not remember ever making such a big and good structure together.',\n",
       " \"The bear couldn't sing ever again.\",\n",
       " 'She worried that she might not ever find another heart that was as beautiful as the',\n",
       " 'Annie waved goodbye and she was sure she would not ever forget this amazing creature',\n",
       " 'Mia did not ever want to be in this place again.',\n",
       " 'Mia did not ever want to be in this place again.',\n",
       " 'The girl did not ever want to drop ice again.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_sents = []\n",
    "for sentence in sentences_df[\"Top 50 Augmented\"]:\n",
    "    for text in sentence:\n",
    "        # print unique occurrences of phrase\n",
    "        if phrase.search(text):\n",
    "            # if text not in neg_sents:\n",
    "            neg_sents.append(text)\n",
    "neg_sents   \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She did not want to see Max ever again.\n",
      "They did not want to see the judge ever again.\n",
      "Lucy was not anxious anymore, and they lived happily ever after.\n",
      "He said they could not play with the microscope ever again.\n",
      "He said they could not play with the microscope ever again.\n",
      "They are not the best toys ever.\n",
      "She smiled and promised not to be naughty ever again.\n",
      "He helped the bear and was not scared ever again.\n",
      "They are not the best toys ever.\n",
      "They are not the best toys ever.\n",
      "They are not the best toys ever.\n",
      "They are not the best toys ever.\n",
      "They have not been played with ever.\"\n",
      "He said they could not play with the microscope ever again.\n",
      "I do not want to fight ever again!\"\n",
      "She did not want to see Max ever again.\n",
      "She smiled and promised not to be naughty ever again.\n",
      "He said they could not play with the microscope ever again.\n",
      "I do not want to fight ever again!\"\n",
      "The bear couldn't sing ever again.\n",
      "He helped the bear and was not scared ever again.\n",
      "He learned his lesson and never tried to take something he couldn't handle ever again\n",
      "They are not the best toys ever.\n",
      "They have not been played with ever.\"\n",
      "He learned his lesson and never tried to take something he couldn't handle ever again\n",
      "They are not the best toys ever.\n",
      "He said they could not play with the microscope ever again.\n",
      "Lucy was not anxious anymore, and they lived happily ever after.\n",
      "This bear was not just any bear; it was the best bear ever!\n",
      "They are not the best toys ever.\n",
      "They played later, but not ever like this before!\n",
      "I won't come back here ever again\".\n",
      "I do not want to fight ever again!\"\n",
      "She did not want to eat olives ever again.\n",
      "He said they could not play with the microscope ever again.\n",
      "They are not the best toys ever.\n",
      "He said they could not play with the microscope ever again.\n",
      "I do not want to fight ever again!\"\n",
      "I do not want to fight ever again!\"\n",
      "He said they could not play with the microscope ever again.\n",
      "“No, I have not seen one ever!” \n",
      "\n",
      "\n",
      "She did not want to see Max ever again.\n",
      "They are not the best toys ever.\n",
      "The people were not scared anymore, and they all lived happily ever after.\n",
      "They are not the best toys ever.\n",
      "She did not want to see Max ever again.\n",
      "The people were not scared anymore, and they all lived happily ever after.\n",
      "I do not want to fight ever again!\"\n",
      "He said they could not play with the microscope ever again.\n",
      "She did not want to see Max ever again.\n",
      "They are not the best toys ever.\n",
      "The people were not scared anymore, and they all lived happily ever after.\n",
      "“No, I have not seen one ever!” \n",
      "\n",
      "\n",
      "I do not want to fight ever again!\"\n",
      "He said they could not play with the microscope ever again.\n",
      "Tim looked at it and said, “You will not move ever again,\n",
      "He didn't come back to the park ever again.\n",
      "They did not want to see the judge ever again.\n",
      "He did not want to see it ever again.\n",
      "They are not the best toys ever.\n",
      "The people were not scared anymore, and they all lived happily ever after.\n",
      "Lucy was not anxious anymore, and they lived happily ever after.\n",
      "I do not want to fight ever again!\"\n",
      "The knot was not just a knot; it was the best game ever!\n",
      "They have not been played with ever.\"\n",
      "The little fish was careful not to ever forget the feeling of being in the net\n",
      "She worried that she might not ever find another heart that was as beautiful as the\n",
      "He said they could not play with the microscope ever again.\n",
      "I do not want to fight ever again!\"\n",
      "They have not been played with ever.\"\n",
      "They are not the best toys ever.\n",
      "They are not the best toys ever.\n",
      "I do not want to fight ever again!\"\n",
      "He said they could not play with the microscope ever again.\n",
      "She did not want to see Max ever again.\n",
      "They did not want to see the judge ever again.\n",
      "She did not want to eat olives ever again.\n",
      "They are not the best toys ever.\n",
      "I do not want to fight ever again!\"\n",
      "He said they could not play with the microscope ever again.\n",
      "I do not want to fight ever again!\"\n",
      "They are not the best toys ever.\n",
      "I do not want to fight ever again!\"\n",
      "They are not the best toys ever.\n",
      "I do not want to fight ever again!\"\n",
      "He learned his lesson and never tried to take something he couldn't handle ever again\n",
      "She knew that nightmares would not scare her ever again!\n",
      "He said they could not play with the microscope ever again.\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences_df[\"Bottom 50 Augmented\"]:\n",
    "    for text in sentence:\n",
    "        if phrase.search(text):\n",
    "            print(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She did not want to see Max ever again.\n",
      "They did not want to see the judge ever again.\n",
      "Lucy was not anxious anymore, and they lived happily ever after.\n",
      "He said they could not play with the microscope ever again.\n",
      "He said they could not play with the microscope ever again.\n",
      "They are not the best toys ever.\n",
      "She smiled and promised not to be naughty ever again.\n",
      "He helped the bear and was not scared ever again.\n",
      "They are not the best toys ever.\n",
      "They are not the best toys ever.\n",
      "They are not the best toys ever.\n",
      "They are not the best toys ever.\n",
      "They have not been played with ever.\"\n",
      "He said they could not play with the microscope ever again.\n",
      "I do not want to fight ever again!\"\n",
      "She did not want to see Max ever again.\n",
      "She smiled and promised not to be naughty ever again.\n",
      "He said they could not play with the microscope ever again.\n",
      "I do not want to fight ever again!\"\n",
      "The bear couldn't sing ever again.\n",
      "He helped the bear and was not scared ever again.\n",
      "He learned his lesson and never tried to take something he couldn't handle ever again\n",
      "They are not the best toys ever.\n",
      "They have not been played with ever.\"\n",
      "He learned his lesson and never tried to take something he couldn't handle ever again\n",
      "They are not the best toys ever.\n",
      "He said they could not play with the microscope ever again.\n",
      "Lucy was not anxious anymore, and they lived happily ever after.\n",
      "This bear was not just any bear; it was the best bear ever!\n",
      "They are not the best toys ever.\n",
      "They played later, but not ever like this before!\n",
      "I won't come back here ever again\".\n",
      "I do not want to fight ever again!\"\n",
      "She did not want to eat olives ever again.\n",
      "He said they could not play with the microscope ever again.\n",
      "They are not the best toys ever.\n",
      "He said they could not play with the microscope ever again.\n",
      "I do not want to fight ever again!\"\n",
      "I do not want to fight ever again!\"\n",
      "He said they could not play with the microscope ever again.\n",
      "“No, I have not seen one ever!” \n",
      "\n",
      "\n",
      "She did not want to see Max ever again.\n",
      "They are not the best toys ever.\n",
      "The people were not scared anymore, and they all lived happily ever after.\n",
      "They are not the best toys ever.\n",
      "She did not want to see Max ever again.\n",
      "The people were not scared anymore, and they all lived happily ever after.\n",
      "I do not want to fight ever again!\"\n",
      "I do not want to fight ever again!\"\n",
      "He said they could not play with the microscope ever again.\n",
      "She did not want to see Max ever again.\n",
      "They are not the best toys ever.\n",
      "The people were not scared anymore, and they all lived happily ever after.\n",
      "I do not want to fight ever again!\"\n",
      "He said they could not play with the microscope ever again.\n",
      "Tim looked at it and said, “You will not move ever again,\n",
      "He didn't come back to the park ever again.\n",
      "They did not want to see the judge ever again.\n",
      "He did not want to see it ever again.\n",
      "They are not the best toys ever.\n",
      "The people were not scared anymore, and they all lived happily ever after.\n",
      "Lucy was not anxious anymore, and they lived happily ever after.\n",
      "I do not want to fight ever again!\"\n",
      "The knot was not just a knot; it was the best game ever!\n",
      "They have not been played with ever.\"\n",
      "The little fish was careful not to ever forget the feeling of being in the net\n",
      "He said they could not play with the microscope ever again.\n",
      "I do not want to fight ever again!\"\n",
      "They have not been played with ever.\"\n",
      "They are not the best toys ever.\n",
      "They are not the best toys ever.\n",
      "I do not want to fight ever again!\"\n",
      "He said they could not play with the microscope ever again.\n",
      "She did not want to see Max ever again.\n",
      "They did not want to see the judge ever again.\n",
      "She did not want to eat olives ever again.\n",
      "They are not the best toys ever.\n",
      "I do not want to fight ever again!\"\n",
      "He said they could not play with the microscope ever again.\n",
      "I do not want to fight ever again!\"\n",
      "They are not the best toys ever.\n",
      "I do not want to fight ever again!\"\n",
      "They are not the best toys ever.\n",
      "I do not want to fight ever again!\"\n",
      "He learned his lesson and never tried to take something he couldn't handle ever again\n",
      "She knew that nightmares would not scare her ever again!\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences_df[\"Bottom 50\"]:\n",
    "    for text in sentence:\n",
    "        if phrase.search(text):\n",
    "            print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# types of NPI with ever: sentential negation, superlative, if/whether, question, subject negated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
